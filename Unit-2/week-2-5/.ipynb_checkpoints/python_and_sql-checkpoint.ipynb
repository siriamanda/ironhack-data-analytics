{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import getpass  # To get the password without showing the input\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing the connection with MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the general syntax 'dialect+driver://username:password@host:port/database'\n",
    "# to create the connection string\n",
    "\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/bank'\n",
    "engine = create_engine(connection_string)\n",
    "data = pd.read_sql_query('SELECT * FROM bank.loan', engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using engine object with executable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = engine.execute('SELECT * FROM bank.loan')\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n",
    "rows = [row for row in result]\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating other databases in our MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running other queries in SQL\n",
    "\n",
    "engine.execute(\"DROP DATABASE IF EXISTS BootCamps\")\n",
    "engine.execute(\"CREATE DATABASE IF NOT EXISTS BootCamps\")\n",
    "engine.execute(\"USE BootCamps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a Panda's dataframe (df) called \"data\" out of a MySQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"USE bank\")\n",
    "query = 'select order_id as \"OrderID\", account_id as \"AccountID\", bank_to as \"DestinationBank\", amount  as \"Amount\" \\\n",
    "from bank.order \\\n",
    "where k_symbol = \"SIPO\" \\\n",
    "limit 100'\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can get the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"select * from bank.trans t \\\n",
    "left join bank.loan l \\\n",
    "on t.account_id = l.account_id \\\n",
    "where l.status in ('A', 'B')\"\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data \n",
    "\n",
    "query = \"select t.type, t.operation, t.amount as t_amount, t.balance, t.k_symbol, \\\n",
    "l.amount as l_amount, l.duration, l.payments, l.status from bank.trans t \\\n",
    "left join bank.loan l \\\n",
    "on t.account_id = l.account_id \\\n",
    "where l.status in ('A', 'B')\"\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the shape and the column types of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataframe has {} rows and {} columns\".format(data.shape[0],data.shape[1]))\n",
    "print()\n",
    "print(\"The data types of each column of the dataframe are:\")\n",
    "print(data.dtypes)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the type of column duration to categorical (nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'] = data['duration'].astype('str')\n",
    "data['duration'] = data['duration'].astype('object') # This will be treated as categorical (ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting basic statistical summary of the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The number of NA's in the dataframe is: \")\n",
    "print(data.isna().sum())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Aparently\" the are not missing values, but already know how nasty the SQL's NULLS are!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking all the categorical columns\n",
    "cols_cat = list(data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "print(\"The categorical columns are: \",cols_cat)\n",
    "print(\"========================================\")\n",
    "print()\n",
    "\n",
    "for col in cols_cat:\n",
    "    print(\"Frequency analysis of column: \",col)\n",
    "    my_data = data[col].value_counts().reset_index()\n",
    "    ax = sns.barplot(x=col, y=\"index\", data = my_data).set_title(col.upper())\n",
    "    plt.figure()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing values in column \"operation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have a lot values for operation which are of type vyber,\n",
    "# we are not removing that data from type column\n",
    "\n",
    "def cleanOperation(x):\n",
    "    x = x.lower()\n",
    "    if 'vyber' in x:\n",
    "        return \"vyber\"\n",
    "    elif 'prevod' in x:\n",
    "        return \"prevod\"\n",
    "    elif 'vklad' in x:\n",
    "        return 'vklad'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data['operation'] = list(map(cleanOperation, data['operation']))\n",
    "data['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing values in column \"k_symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current frequencies of of each value in column 'k_symbol': \",data['k_symbol'].value_counts())\n",
    "print(data['k_symbol'].value_counts().index)\n",
    "\n",
    "def cleankSymbol(x):\n",
    "    if x in ['', ' ']:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "data['k_symbol'] = list(map(cleankSymbol, data['k_symbol']))\n",
    "print(\"Final frequencies of of each value in column 'k_symbol': \",data['k_symbol'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have too much \"unknowns\" and we don't know how to impute them. We drop such rows form the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['k_symbol'].isin(['POJISTINE', 'SANKC. UROK', 'UVER'])]\n",
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values in column \"duration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['duration'].value_counts().index\n",
    "\n",
    "def cleanDuration(x):\n",
    "    if x in ['48', '60']:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return str(x)\n",
    "data['duration'] = list(map(cleanDuration, data['duration']))\n",
    "data['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummifying categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data.select_dtypes(include = np.object)\n",
    "cat = cat.drop(['status'], axis=1)\n",
    "categorical = pd.get_dummies(cat, columns=['type', 'operation', 'k_symbol', 'duration'],drop_first=True)\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix=data.corr(method='pearson')  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember that multicollinearity is not a problem in a logistic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting distributions of numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data['t_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['l_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['balance'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['payments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High skewness!!! Specially for \"t_amount\". With a **linnear model we can't use them as they are**. \n",
    "With a **logistic model YES**, but it will help a lot to get a better model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical columns with different transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.select_dtypes(include = np.number)\n",
    "\n",
    "X1 = X.copy()\n",
    "X2 = X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "transformer = Normalizer().fit(X1)\n",
    "x_normalized = transformer.transform(X1)\n",
    "x_normalized = pd.DataFrame(x_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarizer\n",
    "transformer = StandardScaler().fit(X2)\n",
    "x_standarized = transformer.transform(X2)\n",
    "x_standarized = pd.DataFrame(x_standarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 Key Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1: Independent variables normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['status']\n",
    "X = np.concatenate((x_normalized, categorical), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['status']\n",
    "X = np.concatenate((x_standarized, categorical), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = classification.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"The accuracy of the model on test set is: %4.2f \" % accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "plot_confusion_matrix(classification, X_test, y_test)  # doctest: +SKIP\n",
    "plt.show()  # doctest: +SKIP\n",
    "print(\"The Kappa of your model is: %4.2f\" % (cohen_kappa_score(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
